[![paper tmm](https://img.shields.io/badge/paper-TMM-red)](https://ieeexplore.ieee.org/document/10041721)
![Python 3.8](https://img.shields.io/badge/python-3.8-green?logo=%22python%22)
![OpenSource Love](https://img.shields.io/badge/open%20source-%E2%9D%A4-green)
![GitHub](https://img.shields.io/github/license/XiaoqiWang/VIPNet)

### :v::thumbsup::triangular_flag_on_post: $\mathbb{VIP}$<b>Net</b>: <b>Visual Interaction Perceptual Network</b> for <b> Blind Image Quality Assessment</b>
---
  
### :file_folder: Intro
[Click here for file information](./tree.md)
### :arrows_counterclockwise: Workflow
To retrain DPM, you can either follow the steps below or download the author's pre-trained weights directly.
*  Generate distorted images. Relevant descriptions can be found below.
* Train the distortion perception model by ensuring the correct dataset path and executing the following command:
```bash
bash train_dpm.sh
```
* After training is complete, move the best pre-trained weights to folder **'pretrained_model'**.
  
Next, evaluate the proposed model on IQA datasets using the following steps:
* For a single-dataset test, please refer to the configs.py file for additional parameters. Then, execute the following command:
```bash
bash train.py
```
* For a cross-dataset test, please refer to the configs.py file for additional parameters. Then, execute the following command:
```bash
bash train_cross_datast.sh
```
### :bar_chart: Dataset
* The study generated 30 types of distorted images, of which 25 are identical to those in the KADID-10k dataset and can be obtained by running the dataset_generator.m file in Matlab. 
* The additional four types of distorted images, namely pink noise, contrast change, underexposure, and overexposure, can be generated by running the additional_dataset_generator.m file. 
* The lossy compression distorted images can be downloaded from [this link]().

***Dataset has 6 million images and needs 3TB storage. Pre-trained models can be downloaded if needed.***

###  :gear: Model 
The pre-trained DPM models can be downloaded from [Google Drive](https://drive.google.com/file/d/16owETLc0opC0bbCC4AwVRIEUNi8oAAXm/view?usp=sharing "ÊÇ¨ÂÅúÊòæÁ§∫") or  [Baidu Cloud](https://pan.baidu.com/s/1KZ2On4uLOIhPrhhnxiAd2g?pwd=3y0s "ÊÇ¨ÂÅúÊòæÁ§∫") and save it to folder **'pretrained_model'**.

### :bookmark_tabs: Citation
If our research has been helpful to you, please consider citing our paper in your work.
```bash
@ARTICLE{vipnet_tmm,
  author={Wang, Xiaoqi and Xiong, Jian and Lin, Weisi},
  journal={IEEE Transactions on Multimedia}, 
  title={Visual Interaction Perceptual Network for Blind Image Quality Assessment}, 
  year={2023},
  volume={},
  number={},
  pages={1-13},
  doi={10.1109/TMM.2023.3243683}}

```
### üíñ Acknowledgement
Thanks to the contributors of GitHub repositories [HyperIQA](https://github.com/SSL92/hyperIQA) and [BoTNet](https://github.com/leaderj1001/BottleneckTransformers), whose parts of the code I referenced while developing this project.
